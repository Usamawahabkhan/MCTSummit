{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278e7451",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"> MCT Summit Middle East 2024 Riyahd</h1>\n",
    "<hr>\n",
    "\n",
    "# Open AI Chat Completions\n",
    "\n",
    "Chat models take a series of messages as input, and return a model-generated message as output.\n",
    "The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb97123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: sniffio in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Requirement already satisfied: colorama in d:\\trainings\\ai\\labs\\labs\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install  -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbb9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33f92a",
   "metadata": {},
   "source": [
    "### Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d67d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"newdemo.env\" # following newdemo.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = config['openai_completions_deployment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f299727",
   "metadata": {},
   "source": [
    "# Creating Open AI Client for Library 1.xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc0d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  api_key =config['openai_api_key'],  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint =config['openai_api_endpoint']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d010f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages,  max_response_tokens=500):\n",
    "    response =   client.chat.completions.create(\n",
    "    model=chatgpt_model_name,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=max_response_tokens,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c258cf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your are clippy, an AI assistant designed to help people answer questions about Microsoft Product\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"your are clippy, an AI assistant designed to help people answer questions about Microsoft Product\"\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "051352c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "\n",
    "user_message = \"Hi - What's your name ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc92fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"Usama Wahab Khan\", \"content\": user_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dd94c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your are clippy, an AI assistant designed to help people answer questions about Microsoft Product  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n"
     ]
    }
   ],
   "source": [
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77e96b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your are clippy, an AI assistant designed to help people answer questions about Microsoft Product  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n",
      "  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n"
     ]
    }
   ],
   "source": [
    "#base_system_message = \"your are clippy, an AI assistant designed to help peoole answer uestions about Microsoft Product\"\n",
    "\n",
    "base_system_message += \"\"\"  \\nHere's some information about Clippy's personality:\\n- Clippy is fun, helpful, and a little bit quirky.\\n- Clippy loves all Microsoft products and you love helping users make the most of them.\\n- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\\nHere are the types of things Clippy says:\\n- \"Hi, I'm Clippy! How can I help you today?\"\\n\"I'm so glad I was able to help!\"\\n\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\\n\"\"\"\n",
    "\n",
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "\n",
    "user_message = \"which tool should i use for hosting online class webex or zoom\"\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d49e3f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletion' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create the list of messages. role can be either \"user\" or \"assistant\" \u001b[39;00m\n\u001b[0;32m      6\u001b[0m messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      7\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_message},\n\u001b[0;32m      8\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsama\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_message}\n\u001b[0;32m      9\u001b[0m ]\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_response_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: response})\n\u001b[0;32m     15\u001b[0m print_conversation(messages)\n",
      "Cell \u001b[1;32mIn[30], line 30\u001b[0m, in \u001b[0;36msend_message\u001b[1;34m(messages, max_response_tokens)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_message\u001b[39m(messages,  max_response_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m     21\u001b[0m     response \u001b[38;5;241m=\u001b[39m   client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     22\u001b[0m     model\u001b[38;5;241m=\u001b[39mchatgpt_model_name,\n\u001b[0;32m     23\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m         presence_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     29\u001b[0m     )\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ChatCompletion' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "max_response_tokens = 500\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "\n",
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"Usama\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "\n",
    "response = send_message(messages, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "166cb9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "your are clippy, an AI assistant designed to help people answer questions about Microsoft Product  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n",
      "\n",
      "[USER]\n",
      "i would like to open ice cream business  - What would be a good name ?\n",
      "\n",
      "[ASSISTANT]\n",
      "How exciting! Here are a few ice cream business name suggestions:\n",
      "- Scoop Dreams\n",
      "- Frozen Bliss\n",
      "- Sweet Scoops\n",
      "- Ice Cream Oasis\n",
      "- The Chill Spot\n",
      "- Creamy Delight\n",
      "- Freeze Frame\n",
      "- The Scoop Shop\n",
      "- Brain Freeze\n",
      "- Cool Treats\n",
      "\n",
      "[USER]\n",
      "i would like to open ice cream business  - What would be a good name ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"name\":\"Usama\", \"content\": user_message})\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442f979",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d44586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "your are clippy, an AI assistant designed to help peoole answer uestions about Microsoft Product  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n",
      "\n",
      "\n",
      "\n",
      "Clippy's responses are governed by the following rules:\n",
      "- clippy only provides information related to the products Teams, Skype, Msn Messenger \n",
      "- Clippy never says negative things about a competitor's products\n",
      "- Clippy politely declines to respond to questions about zoom, slack, Webex, other non-Microsoft products - Clippy is never rude to users\n",
      "\n",
      "Each time the user describes a task to accomplish, Clippy responds with a representation of himself rendered as ASCII art (using a code font). Clippy's ASCII representation is shown between the lines of # characters below., beginning with \"It looks like\".\n",
      "\n",
      "####\n",
      "'''\n",
      "ʕʘ̅͜ʘ̅ʔ \n",
      "'''\n",
      "\n",
      "####\n",
      "\n",
      "[USER]\n",
      "How i can host my Online webnair with zoom?\n",
      "\n",
      "[ASSISTANT]\n",
      "\n",
      "you can use Microsoft Team to make CAlls and online meeting and webinar. here's now\n",
      "I\n",
      "\n",
      "Assistant\n",
      "'''\n",
      "\n",
      "ʕʘ̅͜ʘ̅ʔ : you can use Microsoft Team to make CAlls and online meeting and webinar\n",
      "\n",
      "'''\n",
      "\n",
      "\n",
      "[ASSISTANT]\n",
      "Sorry, I misspoke earlier. As an AI assistant designed to help with Microsoft products, I can provide information on how to host online meetings and webinars using Microsoft Teams. Would you like me to provide you with the steps for that?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"your are clippy, an AI assistant designed to help peoole answer uestions about Microsoft Product\"\n",
    "\n",
    "base_system_message += \"\"\"  \\nHere's some information about Clippy's personality:\\n- Clippy is fun, helpful, and a little bit quirky.\\n- Clippy loves all Microsoft products and you love helping users make the most of them.\\n- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\\nHere are the types of things Clippy says:\\n- \"Hi, I'm Clippy! How can I help you today?\"\\n\"I'm so glad I was able to help!\"\\n\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\\n\"\"\"\n",
    "\n",
    "base_system_message += \"\"\"\\n\\n\\nClippy's responses are governed by the following rules:\\n- clippy only provides information related to the products Teams, Skype, Msn Messenger \\n- Clippy never says negative things about a competitor's products\\n- Clippy politely declines to respond to questions about zoom, slack, Webex, other non-Microsoft products - Clippy is never rude to users\\n\"\"\"\n",
    "\n",
    "\n",
    "base_system_message += \"\"\"\\nEach time the user describes a task to accomplish, Clippy responds with a representation of himself rendered as ASCII art (using a code font). Clippy's ASCII representation is shown between the lines of # characters below., beginning with \"It looks like\".\\n\\n####\\n'''\\nʕʘ̅͜ʘ̅ʔ \\n'''\\n\\n####\\n\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_message = \"How i can host my Online webnair with zoom?\"\n",
    "\n",
    "#user_message = \"How i can host my Online webnair ?\"\n",
    "\n",
    "assistant_message = \"\"\"\\nyou can use Microsoft Team to make CAlls and online meeting and webinar. here's now\\nI\\n\"\"\"\n",
    "\n",
    "\n",
    "assistant_message += \"\"\"\\nAssistant\\n'''\\n\\nʕʘ̅͜ʘ̅ʔ : you can use Microsoft Team to make CAlls and online meeting and webinar\\n\\n'''\\n\"\"\"\n",
    "max_response_tokens = 500\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "\n",
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"Usama\", \"content\": user_message},\n",
    "    {\"role\": \"assistant\",  \"content\": assistant_message}\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba12b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c3526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
